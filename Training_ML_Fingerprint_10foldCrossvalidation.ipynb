{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Descriptors import MolLogP\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "import sys\n",
    "import multiprocessing\n",
    "from standardiser import break_bonds, neutralise, rules, unsalt\n",
    "from standardiser.utils import StandardiseException, sanity_check\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "def warn(*args, **kwargs):\n",
    "    pass \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn = warn\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import sys\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import csv\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import _pickle as cPickle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit    \n",
    "import bz2\n",
    "from glob import glob\n",
    "import _pickle as cPickle\n",
    "import pickle\n",
    "# Draw.DrawingOptions.atomLabelFontFace = \"DejaVu Sans\"\n",
    "# Draw.DrawingOptions.atomLabelFontSize = 18\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "                                              SMILES  Outcome  \\\n",
      "0  CCCCCCCCC=CCCCCCCCC(=O)OCC(CC)(CO)COC(=O)CCCCC...        0   \n",
      "1            CC12C=CC(=O)C=C1CCC1C2CCC2(C)C(=O)CCC12        0   \n",
      "2                      CC(C)N(C(=O)SCC(Cl)=CCl)C(C)C        0   \n",
      "3                                    CC1(C)OCC(CO)O1        0   \n",
      "4                                      O=C=Nc1ccccc1        0   \n",
      "\n",
      "                                  Morgan_Descriptors  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                   MACCS_Descriptors  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                     APF_Descriptors  Molecular Weight  \\\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           663.081   \n",
      "1  [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           284.399   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           270.225   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           132.159   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           119.123   \n",
      "\n",
      "      logP   LabuteASA   TPSA      AMW  ...  nHBDon  nAtomLAC  nAtomLC  \\\n",
      "0  12.5365  291.667040  72.83  663.081  ...       1        18       41   \n",
      "1   3.8634  126.228723  34.14  284.399  ...       0         0        0   \n",
      "2   4.2774  105.985125  20.31  270.225  ...       0         3        9   \n",
      "3   0.1302   54.579455  38.69  132.159  ...       1         0        2   \n",
      "4   1.6539   52.853190  29.43  119.123  ...       0         0        3   \n",
      "\n",
      "   PetitjeanNumber  nRotB  LipinskiFailures  TopoPSA   VAdjMat   XLogP  \\\n",
      "0              0.5     38                 3    72.83  6.523562  17.303   \n",
      "1              0.5      0                 0    34.14  5.584963   3.496   \n",
      "2              0.5      6                 0    45.61  4.807355   3.440   \n",
      "3              0.4      1                 0    38.69  4.169925  -0.038   \n",
      "4              0.5      1                 0    29.43  4.169925   3.286   \n",
      "\n",
      "       Fsp3  \n",
      "0  0.857143  \n",
      "1  0.684211  \n",
      "2  0.700000  \n",
      "3  1.000000  \n",
      "4  0.000000  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# Function to read Excel file into DataFrame\n",
    "def load_excel_to_df(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    return df\n",
    "\n",
    "# Convert strings back to lists of integers\n",
    "def string_to_list(bit_string):\n",
    "    if isinstance(bit_string, str):\n",
    "        return list(map(int, bit_string.strip('[]').split(', ')))\n",
    "    else:\n",
    "        return bit_string\n",
    "\n",
    "# Load Excel file\n",
    "train_df = load_excel_to_df(r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Train_set_Dermal_balanced_with_fingerprints_sorted_with_RDKit_and_CDK_features.xlsx\")\n",
    "\n",
    "# Apply the string-to-list conversion for the fingerprint columns\n",
    "fingerprint_columns = ['Morgan_Descriptors', 'MACCS_Descriptors', 'APF_Descriptors']\n",
    "for col in fingerprint_columns:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].apply(string_to_list)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} not found in Excel file!\")\n",
    "\n",
    "# Define combined_df as train_df\n",
    "combined_df = train_df\n",
    "\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMILES', 'Outcome', 'Morgan_Descriptors', 'MACCS_Descriptors',\n",
       "       'APF_Descriptors', 'Molecular Weight', 'logP', 'LabuteASA', 'TPSA',\n",
       "       'AMW', 'NumRotatableBonds', 'NumAromaticRings', 'NumSaturatedRings',\n",
       "       'NumAliphaticRings', 'NumAromaticHeterocycles',\n",
       "       'NumSaturatedHeterocycles', 'NumAliphaticHeterocycles',\n",
       "       'NumAromaticCarbocycles', 'NumSaturatedCarbocycles',\n",
       "       'NumAliphaticCarbocycles', 'FractionCSP3', 'Chi0v', 'Chi1v', 'Chi2v',\n",
       "       'Chi3v', 'Chi4v', 'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n', 'HallKierAlpha',\n",
       "       'Heavy Atom Count', 'Ring Count', 'Num H Donors', 'Num H Acceptors',\n",
       "       'ALogP', 'ALogp2', 'AMR', 'MLogP', 'nAtomP', 'naAromAtom', 'bpol', 'nB',\n",
       "       'ECCEN', 'fragC', 'nHBAcc', 'nHBDon', 'nAtomLAC', 'nAtomLC',\n",
       "       'PetitjeanNumber', 'nRotB', 'LipinskiFailures', 'TopoPSA', 'VAdjMat',\n",
       "       'XLogP', 'Fsp3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Morgan_Descriptors</th>\n",
       "      <th>MACCS_Descriptors</th>\n",
       "      <th>APF_Descriptors</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>logP</th>\n",
       "      <th>LabuteASA</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>AMW</th>\n",
       "      <th>...</th>\n",
       "      <th>nAtomLAC</th>\n",
       "      <th>nAtomLC</th>\n",
       "      <th>PetitjeanNumber</th>\n",
       "      <th>nRotB</th>\n",
       "      <th>LipinskiFailures</th>\n",
       "      <th>TopoPSA</th>\n",
       "      <th>VAdjMat</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Fsp3</th>\n",
       "      <th>RowID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCCCCCCC=CCCCCCCCC(=O)OCC(CC)(CO)COC(=O)CCCCC...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>663.081</td>\n",
       "      <td>12.5365</td>\n",
       "      <td>291.667040</td>\n",
       "      <td>72.83</td>\n",
       "      <td>663.081</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>72.83</td>\n",
       "      <td>6.523562</td>\n",
       "      <td>17.303</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC12C=CC(=O)C=C1CCC1C2CCC2(C)C(=O)CCC12</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>284.399</td>\n",
       "      <td>3.8634</td>\n",
       "      <td>126.228723</td>\n",
       "      <td>34.14</td>\n",
       "      <td>284.399</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.14</td>\n",
       "      <td>5.584963</td>\n",
       "      <td>3.496</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)N(C(=O)SCC(Cl)=CCl)C(C)C</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>270.225</td>\n",
       "      <td>4.2774</td>\n",
       "      <td>105.985125</td>\n",
       "      <td>20.31</td>\n",
       "      <td>270.225</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>45.61</td>\n",
       "      <td>4.807355</td>\n",
       "      <td>3.440</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1(C)OCC(CO)O1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>132.159</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>54.579455</td>\n",
       "      <td>38.69</td>\n",
       "      <td>132.159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.69</td>\n",
       "      <td>4.169925</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C=Nc1ccccc1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>119.123</td>\n",
       "      <td>1.6539</td>\n",
       "      <td>52.853190</td>\n",
       "      <td>29.43</td>\n",
       "      <td>119.123</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.43</td>\n",
       "      <td>4.169925</td>\n",
       "      <td>3.286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>OCCCCCCCCCCO</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>174.284</td>\n",
       "      <td>2.0918</td>\n",
       "      <td>75.612198</td>\n",
       "      <td>40.46</td>\n",
       "      <td>174.284</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>40.46</td>\n",
       "      <td>4.459432</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>O=[N+]([O-])NC1=NCCN1Cc1ccc(Cl)nc1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>255.665</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>102.236385</td>\n",
       "      <td>83.66</td>\n",
       "      <td>255.665</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>83.66</td>\n",
       "      <td>5.169925</td>\n",
       "      <td>2.294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CCCCOCCOP(=O)(OCCOCCCC)OCCOCCCC</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>398.477</td>\n",
       "      <td>4.5944</td>\n",
       "      <td>159.174149</td>\n",
       "      <td>72.45</td>\n",
       "      <td>398.477</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>82.26</td>\n",
       "      <td>5.643856</td>\n",
       "      <td>2.790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>O=C(CO)Oc1ccc(Cl)cc1Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>221.039</td>\n",
       "      <td>1.8911</td>\n",
       "      <td>84.837121</td>\n",
       "      <td>46.53</td>\n",
       "      <td>221.039</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>46.53</td>\n",
       "      <td>4.700440</td>\n",
       "      <td>2.014</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CCS</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>62.137</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>26.259260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.137</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.80</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               SMILES  Outcome  \\\n",
       "0   CCCCCCCCC=CCCCCCCCC(=O)OCC(CC)(CO)COC(=O)CCCCC...        0   \n",
       "1             CC12C=CC(=O)C=C1CCC1C2CCC2(C)C(=O)CCC12        0   \n",
       "2                       CC(C)N(C(=O)SCC(Cl)=CCl)C(C)C        0   \n",
       "3                                     CC1(C)OCC(CO)O1        0   \n",
       "4                                       O=C=Nc1ccccc1        0   \n",
       "..                                                ...      ...   \n",
       "95                                       OCCCCCCCCCCO        0   \n",
       "96                 O=[N+]([O-])NC1=NCCN1Cc1ccc(Cl)nc1        0   \n",
       "97                    CCCCOCCOP(=O)(OCCOCCCC)OCCOCCCC        0   \n",
       "98                             O=C(CO)Oc1ccc(Cl)cc1Cl        0   \n",
       "99                                                CCS        0   \n",
       "\n",
       "                                   Morgan_Descriptors  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                ...   \n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "96  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "97  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "98  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    MACCS_Descriptors  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                ...   \n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "96  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "97  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "98  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      APF_Descriptors  Molecular Weight  \\\n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           663.081   \n",
       "1   [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           284.399   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           270.225   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           132.159   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           119.123   \n",
       "..                                                ...               ...   \n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           174.284   \n",
       "96  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           255.665   \n",
       "97  [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...           398.477   \n",
       "98  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           221.039   \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            62.137   \n",
       "\n",
       "       logP   LabuteASA   TPSA      AMW  ...  nAtomLAC  nAtomLC  \\\n",
       "0   12.5365  291.667040  72.83  663.081  ...        18       41   \n",
       "1    3.8634  126.228723  34.14  284.399  ...         0        0   \n",
       "2    4.2774  105.985125  20.31  270.225  ...         3        9   \n",
       "3    0.1302   54.579455  38.69  132.159  ...         0        2   \n",
       "4    1.6539   52.853190  29.43  119.123  ...         0        3   \n",
       "..      ...         ...    ...      ...  ...       ...      ...   \n",
       "95   2.0918   75.612198  40.46  174.284  ...        10       12   \n",
       "96   0.6879  102.236385  83.66  255.665  ...         0        3   \n",
       "97   4.5944  159.174149  72.45  398.477  ...         4       17   \n",
       "98   1.8911   84.837121  46.53  221.039  ...         2        4   \n",
       "99   0.9361   26.259260   0.00   62.137  ...         2        3   \n",
       "\n",
       "    PetitjeanNumber  nRotB  LipinskiFailures  TopoPSA   VAdjMat   XLogP  \\\n",
       "0          0.500000     38                 3    72.83  6.523562  17.303   \n",
       "1          0.500000      0                 0    34.14  5.584963   3.496   \n",
       "2          0.500000      6                 0    45.61  4.807355   3.440   \n",
       "3          0.400000      1                 0    38.69  4.169925  -0.038   \n",
       "4          0.500000      1                 0    29.43  4.169925   3.286   \n",
       "..              ...    ...               ...      ...       ...     ...   \n",
       "95         0.454545      9                 0    40.46  4.459432   2.500   \n",
       "96         0.500000      4                 0    83.66  5.169925   2.294   \n",
       "97         0.500000     21                 1    82.26  5.643856   2.790   \n",
       "98         0.500000      3                 0    46.53  4.700440   2.014   \n",
       "99         0.500000      0                 0    38.80  2.000000   1.305   \n",
       "\n",
       "        Fsp3  RowID  \n",
       "0   0.857143      0  \n",
       "1   0.684211      1  \n",
       "2   0.700000      2  \n",
       "3   1.000000      3  \n",
       "4   0.000000      4  \n",
       "..       ...    ...  \n",
       "95  1.000000     95  \n",
       "96  0.333333     96  \n",
       "97  1.000000     97  \n",
       "98  0.125000     98  \n",
       "99  1.000000     99  \n",
       "\n",
       "[100 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df= combined_df.sort_values(['Outcome'], ascending=True)\n",
    "combined_df['RowID'] = combined_df.index\n",
    "combined_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes                          :  [0 1]\n",
      "Number of cpds in each class     :  [305 306]\n",
      "Total number of cpds             :  611\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "outcomes = np.unique(combined_df['Outcome'])\n",
    "le.fit(outcomes)\n",
    "y = le.transform(combined_df['Outcome'])\n",
    "\n",
    "# Hasil\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(\"Classes                          : \", classes)\n",
    "print(\"Number of cpds in each class     : \", counts)\n",
    "print(\"Total number of cpds             : \", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.Series(le.transform(combined_df['Outcome']))  # Sama dengan y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x190bef1a3c0>,\n",
       " <matplotlib.axis.XTick at 0x190bef1a390>,\n",
       " <matplotlib.axis.XTick at 0x190bee526c0>,\n",
       " <matplotlib.axis.XTick at 0x190bef52a50>,\n",
       " <matplotlib.axis.XTick at 0x190bef533b0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = S.hist(bins=np.arange(-0.5,5))\n",
    "ax.set_xticks(range(0,5))\n",
    "#info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y = np.int32(S)  # pastikan S sudah didefinisikan\n",
    "\n",
    "# Fingerprint arrays\n",
    "x_maccs = np.array(list(combined_df['MACCS_Descriptors']))\n",
    "x_morgan = np.array(list(combined_df['Morgan_Descriptors']))\n",
    "x_apf = np.array(list(combined_df['APF_Descriptors']))  # ditambahkan APF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.7233\n",
      "CV AUC: 0.8177\n",
      "CV Precision: 0.7439\n",
      "CV Recall (Sensitivity): 0.6823\n",
      "CV F1: 0.7091\n",
      "CV Specificity: 0.7640\n",
      "CV PPV: 0.7439\n",
      "CV NPV: 0.7098\n",
      "CV CCR: 0.7231\n",
      "Final Random Forest model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_rf_morgan_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# 1️⃣ Define features and target\n",
    "# ==========================\n",
    "# x_morgan, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# 2️⃣ Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_morgan.shape[1], x_morgan.shape[1] // 2, x_morgan.shape[1] // 4, x_morgan.shape[1] // 12, x_morgan.shape[1] // 10,\n",
    "        x_morgan.shape[1] // 7, x_morgan.shape[1] // 5, x_morgan.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# 3️⃣ Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 4️⃣ Cross-validation for performance reporting\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# 5️⃣ Loop CV to evaluate performance\n",
    "# ==========================\n",
    "for train_idx, test_idx in cv.split(x_morgan, y):\n",
    "    X_train, X_test = x_morgan[train_idx], x_morgan[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # GridSearchCV untuk hyperparameter terbaik\n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,  \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    # Prediksi fold test\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# 6️⃣ Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# 7️⃣ Train final model on full dataset\n",
    "# ==========================\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_morgan, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# 8️⃣ Save final model\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_path = os.path.join(model_folder, 'FDAMDD_rf_morgan.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# ==========================\n",
    "# 9️⃣ Save CV metrics report\n",
    "# ==========================\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_morgan_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACCS_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:   0%|                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  10%|██████▋                                                            | 1/10 [00:20<03:07, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  20%|█████████████▍                                                     | 2/10 [00:41<02:46, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  30%|████████████████████                                               | 3/10 [01:02<02:26, 20.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  40%|██████████████████████████▊                                        | 4/10 [01:13<01:40, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  50%|█████████████████████████████████▌                                 | 5/10 [01:28<01:20, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  60%|████████████████████████████████████████▏                          | 6/10 [01:45<01:05, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  70%|██████████████████████████████████████████████▉                    | 7/10 [02:06<00:53, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  80%|█████████████████████████████████████████████████████▌             | 8/10 [02:24<00:36, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  90%|████████████████████████████████████████████████████████████▎      | 9/10 [02:42<00:18, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds: 100%|██████████████████████████████████████████████████████████████████| 10/10 [02:59<00:00, 17.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.7561\n",
      "CV AUC: 0.8447\n",
      "CV Precision: 0.7803\n",
      "CV Recall (Sensitivity): 0.7188\n",
      "CV F1: 0.7469\n",
      "CV Specificity: 0.7931\n",
      "CV PPV: 0.7803\n",
      "CV NPV: 0.7383\n",
      "CV CCR: 0.7560\n",
      "Training final model on full dataset...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Final Random Forest model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_rf_macckeys_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_maccs, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_maccs.shape[1], x_maccs.shape[1] // 2, x_maccs.shape[1] // 4,\n",
    "        x_maccs.shape[1] // 12, x_maccs.shape[1] // 10,\n",
    "        x_maccs.shape[1] // 7, x_maccs.shape[1] // 5, x_maccs.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress bar\n",
    "# ==========================\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_maccs, y), total=cv.get_n_splits(), desc=\"Outer CV folds\")):\n",
    "    X_train, X_test = x_maccs[train_idx], x_maccs[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"Training final model on full dataset...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_final.fit(x_maccs, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(model_folder, 'FDAMDD_rf_macckeys.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# ==========================\n",
    "# Save CV metrics report\n",
    "# ==========================\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_macckeys_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APF_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:   0%|                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  10%|██████▋                                                            | 1/10 [00:42<06:25, 42.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  20%|█████████████▍                                                     | 2/10 [01:26<05:48, 43.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  30%|████████████████████                                               | 3/10 [02:10<05:04, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  40%|██████████████████████████▊                                        | 4/10 [02:56<04:28, 44.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  50%|█████████████████████████████████▌                                 | 5/10 [03:40<03:41, 44.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  60%|████████████████████████████████████████▏                          | 6/10 [04:20<02:52, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  70%|██████████████████████████████████████████████▉                    | 7/10 [04:55<02:00, 40.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  80%|█████████████████████████████████████████████████████▌             | 8/10 [05:30<01:17, 38.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds:  90%|████████████████████████████████████████████████████████████▎      | 9/10 [06:06<00:37, 37.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV folds: 100%|██████████████████████████████████████████████████████████████████| 10/10 [06:45<00:00, 40.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.7495\n",
      "CV AUC: 0.8085\n",
      "CV Precision: 0.7859\n",
      "CV Recall (Sensitivity): 0.6958\n",
      "CV F1: 0.7340\n",
      "CV Specificity: 0.8033\n",
      "CV PPV: 0.7859\n",
      "CV NPV: 0.7281\n",
      "CV CCR: 0.7496\n",
      "Training final model on full dataset...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Final Random Forest model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_rf_apf_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_apf, y sudah didefinisikan sebelumnya\n",
    "# Pastikan y = np.int32(S)\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_apf.shape[1], x_apf.shape[1] // 2, x_apf.shape[1] // 4,\n",
    "        x_apf.shape[1] // 12, x_apf.shape[1] // 10,\n",
    "        x_apf.shape[1] // 7, x_apf.shape[1] // 5, x_apf.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress bar\n",
    "# ==========================\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_apf, y), total=cv.get_n_splits(), desc=\"Outer CV folds\")):\n",
    "    X_train, X_test = x_apf[train_idx], x_apf[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"Training final model on full dataset...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_final.fit(x_apf, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics report\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_rf_apf.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_apf_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_XBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10-fold cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|                                                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  10%|███████▎                                                                 | 1/10 [00:12<01:56, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  20%|██████████████▌                                                          | 2/10 [00:24<01:35, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  30%|█████████████████████▉                                                   | 3/10 [00:33<01:13, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  40%|█████████████████████████████▏                                           | 4/10 [00:44<01:06, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  50%|████████████████████████████████████▌                                    | 5/10 [00:56<00:55, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  60%|███████████████████████████████████████████▊                             | 6/10 [01:05<00:42, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  70%|███████████████████████████████████████████████████                      | 7/10 [01:12<00:28,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  80%|██████████████████████████████████████████████████████████▍              | 8/10 [01:20<00:17,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  90%|█████████████████████████████████████████████████████████████████▋       | 9/10 [01:27<00:08,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [01:34<00:00,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "\n",
      "=== 10-Fold CV Metrics ===\n",
      "Accuracy: 0.7397\n",
      "AUC: 0.8057\n",
      "Precision: 0.7496\n",
      "Recall (Sensitivity): 0.7251\n",
      "F1: 0.7356\n",
      "Specificity: 0.7543\n",
      "PPV: 0.7496\n",
      "NPV: 0.7341\n",
      "CCR: 0.7397\n",
      "\n",
      "Training final XGBoost model on full dataset with GridSearchCV...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_xgb_morgan_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_morgan, y sudah didefinisikan sebelumnya\n",
    "# Pastikan y = np.int32(S) jika perlu\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_morgan, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_morgan[train_idx], x_morgan[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset with GridSearchCV...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_morgan, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_morgan.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_morgan_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACCS_XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10-fold cross-validation for MACCS features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|                                                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  10%|███████▎                                                                 | 1/10 [00:02<00:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  20%|██████████████▌                                                          | 2/10 [00:04<00:17,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  30%|█████████████████████▉                                                   | 3/10 [00:06<00:14,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  40%|█████████████████████████████▏                                           | 4/10 [00:08<00:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  50%|████████████████████████████████████▌                                    | 5/10 [00:10<00:10,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  60%|███████████████████████████████████████████▊                             | 6/10 [00:12<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  70%|███████████████████████████████████████████████████                      | 7/10 [00:14<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  80%|██████████████████████████████████████████████████████████▍              | 8/10 [00:16<00:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  90%|█████████████████████████████████████████████████████████████████▋       | 9/10 [00:18<00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "\n",
      "=== 10-Fold CV Metrics for MACCS ===\n",
      "Accuracy: 0.7528\n",
      "AUC: 0.8358\n",
      "Precision: 0.7584\n",
      "Recall (Sensitivity): 0.7480\n",
      "F1: 0.7500\n",
      "Specificity: 0.7578\n",
      "PPV: 0.7584\n",
      "NPV: 0.7550\n",
      "CCR: 0.7529\n",
      "\n",
      "Training final XGBoost model on full dataset (MACCS features)...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_xgb_maccs_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_maccs, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation for MACCS features...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_maccs, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_maccs[train_idx], x_maccs[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics for MACCS ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset (MACCS features)...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_maccs, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_maccs.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_maccs_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APF_XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10-fold cross-validation for APF features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|                                                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  10%|███████▎                                                                 | 1/10 [00:08<01:17,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  20%|██████████████▌                                                          | 2/10 [00:17<01:08,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  30%|█████████████████████▉                                                   | 3/10 [00:25<01:00,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  40%|█████████████████████████████▏                                           | 4/10 [00:35<00:53,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  50%|████████████████████████████████████▌                                    | 5/10 [00:44<00:44,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  60%|███████████████████████████████████████████▊                             | 6/10 [00:52<00:34,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  70%|███████████████████████████████████████████████████                      | 7/10 [01:00<00:25,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  80%|██████████████████████████████████████████████████████████▍              | 8/10 [01:08<00:16,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:  90%|█████████████████████████████████████████████████████████████████▋       | 9/10 [01:19<00:09,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [01:28<00:00,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "\n",
      "=== 10-Fold CV Metrics for APF ===\n",
      "Accuracy: 0.6987\n",
      "AUC: 0.7854\n",
      "Precision: 0.6948\n",
      "Recall (Sensitivity): 0.7153\n",
      "F1: 0.7019\n",
      "Specificity: 0.6816\n",
      "PPV: 0.6948\n",
      "NPV: 0.7101\n",
      "CCR: 0.6984\n",
      "\n",
      "Training final XGBoost model on full dataset (APF features)...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost model saved successfully!\n",
      "CV metrics report saved successfully at: C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_xgb_apf_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_apf, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation for APF features...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_apf, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_apf[train_idx], x_apf[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics for APF ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset (APF features)...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_apf, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_apf.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_apf_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_MACCS_APF_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Morgan features =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:   0%|                                                                          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  10%|██████▌                                                           | 1/10 [00:31<04:46, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  20%|█████████████▏                                                    | 2/10 [01:02<04:07, 30.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  30%|███████████████████▊                                              | 3/10 [01:33<03:37, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  40%|██████████████████████████▍                                       | 4/10 [02:03<03:03, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  50%|█████████████████████████████████                                 | 5/10 [02:33<02:31, 30.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  60%|███████████████████████████████████████▌                          | 6/10 [03:03<02:00, 30.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  70%|██████████████████████████████████████████████▏                   | 7/10 [03:32<01:29, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  80%|████████████████████████████████████████████████████▊             | 8/10 [04:01<00:59, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds:  90%|███████████████████████████████████████████████████████████▍      | 9/10 [04:32<00:29, 29.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan CV Folds: 100%|█████████████████████████████████████████████████████████████████| 10/10 [05:01<00:00, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "=== 10-Fold CV Metrics for Morgan ===\n",
      "Accuracy: 0.7347\n",
      "AUC: 0.8100\n",
      "Precision: 0.7500\n",
      "Recall (Sensitivity): 0.7052\n",
      "F1: 0.7261\n",
      "Specificity: 0.7639\n",
      "PPV: 0.7500\n",
      "NPV: 0.7225\n",
      "CCR: 0.7345\n",
      "\n",
      "Training final SVM model on full dataset (Morgan features)...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model for Morgan saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_Morgan.pkl\n",
      "CV metrics report saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_Morgan_CV_metrics.xlsx\n",
      "\n",
      "===== Processing MACCS features =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:   0%|                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  10%|██████▋                                                            | 1/10 [00:07<01:05,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  20%|█████████████▍                                                     | 2/10 [00:12<00:50,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  30%|████████████████████                                               | 3/10 [00:18<00:42,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  40%|██████████████████████████▊                                        | 4/10 [00:25<00:37,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  50%|█████████████████████████████████▌                                 | 5/10 [00:31<00:31,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  60%|████████████████████████████████████████▏                          | 6/10 [00:37<00:25,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  70%|██████████████████████████████████████████████▉                    | 7/10 [00:44<00:19,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  80%|█████████████████████████████████████████████████████▌             | 8/10 [00:49<00:12,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds:  90%|████████████████████████████████████████████████████████████▎      | 9/10 [00:55<00:05,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS CV Folds: 100%|██████████████████████████████████████████████████████████████████| 10/10 [01:00<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "=== 10-Fold CV Metrics for MACCS ===\n",
      "Accuracy: 0.7512\n",
      "AUC: 0.8354\n",
      "Precision: 0.7503\n",
      "Recall (Sensitivity): 0.7577\n",
      "F1: 0.7524\n",
      "Specificity: 0.7441\n",
      "PPV: 0.7503\n",
      "NPV: 0.7565\n",
      "CCR: 0.7509\n",
      "\n",
      "Training final SVM model on full dataset (MACCS features)...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model for MACCS saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_MACCS.pkl\n",
      "CV metrics report saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_MACCS_CV_metrics.xlsx\n",
      "\n",
      "===== Processing APF features =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:   0%|                                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  10%|██████▉                                                              | 1/10 [00:26<04:01, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  20%|█████████████▊                                                       | 2/10 [00:54<03:36, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done. Best params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  30%|████████████████████▋                                                | 3/10 [01:21<03:09, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  40%|███████████████████████████▌                                         | 4/10 [01:47<02:40, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  50%|██████████████████████████████████▌                                  | 5/10 [02:14<02:14, 26.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done. Best params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  60%|█████████████████████████████████████████▍                           | 6/10 [02:41<01:48, 27.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done. Best params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  70%|████████████████████████████████████████████████▎                    | 7/10 [03:08<01:21, 27.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  80%|███████████████████████████████████████████████████████▏             | 8/10 [03:35<00:54, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds:  90%|██████████████████████████████████████████████████████████████       | 9/10 [04:03<00:27, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "APF CV Folds: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:29<00:00, 26.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done. Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "=== 10-Fold CV Metrics for APF ===\n",
      "Accuracy: 0.7168\n",
      "AUC: 0.7977\n",
      "Precision: 0.7075\n",
      "Recall (Sensitivity): 0.7412\n",
      "F1: 0.7222\n",
      "Specificity: 0.6915\n",
      "PPV: 0.7075\n",
      "NPV: 0.7317\n",
      "CCR: 0.7163\n",
      "\n",
      "Training final SVM model on full dataset (APF features)...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model for APF saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_APF.pkl\n",
      "CV metrics report saved at:\n",
      "C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model\\Dermal_SVM_APF_CV_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# Pastikan x_morgan, x_maccs, x_apf, dan y sudah didefinisikan sebelumnya\n",
    "feature_sets = {\n",
    "    \"Morgan\": x_morgan,\n",
    "    \"MACCS\": x_maccs,\n",
    "    \"APF\": x_apf\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid SVM\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    \"gamma\": ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# CV setup\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Output folder\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# Loop untuk tiap feature set\n",
    "# ==========================\n",
    "for name, X in feature_sets.items():\n",
    "    print(f\"\\n===== Processing {name} features =====\")\n",
    "    \n",
    "    accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "    specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(X, y), total=10, desc=f\"{name} CV Folds\")):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            estimator=SVC(probability=True),\n",
    "            param_grid=paramgrid,\n",
    "            scoring=kappa_scorer,\n",
    "            cv=5,\n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Metrics\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "        precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        confusion_matrices.append(cm)\n",
    "        \n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        \n",
    "        ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "        npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "        ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "        \n",
    "        print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "    \n",
    "    # ==========================\n",
    "    # Report metrics\n",
    "    # ==========================\n",
    "    cv_metrics = {\n",
    "        \"Accuracy\": np.mean(accuracies),\n",
    "        \"AUC\": np.mean(auc_scores),\n",
    "        \"Precision\": np.mean(precisions),\n",
    "        \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "        \"F1\": np.mean(f1_scores),\n",
    "        \"Specificity\": np.mean(specificities),\n",
    "        \"PPV\": np.mean(ppvs),\n",
    "        \"NPV\": np.mean(npvs),\n",
    "        \"CCR\": np.mean(ccrs)\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== 10-Fold CV Metrics for {name} ===\")\n",
    "    for k, v in cv_metrics.items():\n",
    "        print(f'{k}: {v:.4f}')\n",
    "\n",
    "    # ==========================\n",
    "    # Train full dataset dengan best hyperparameter\n",
    "    # ==========================\n",
    "    print(f\"\\nTraining final SVM model on full dataset ({name} features)...\")\n",
    "    grid_final = GridSearchCV(\n",
    "        estimator=SVC(probability=True),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_final.fit(X, y)\n",
    "    final_model = grid_final.best_estimator_\n",
    "    \n",
    "    # ==========================\n",
    "    # Save model & metrics\n",
    "    # ==========================\n",
    "    model_path = os.path.join(model_folder, f'Dermal_SVM_{name}.pkl')\n",
    "    joblib.dump(final_model, model_path, compress=9)\n",
    "    \n",
    "    metrics_df = pd.DataFrame([cv_metrics])\n",
    "    metrics_path = os.path.join(model_folder, f'Dermal_SVM_{name}_CV_metrics.xlsx')\n",
    "    metrics_df.to_excel(metrics_path, index=False)\n",
    "    \n",
    "    print(f\"Final SVM model for {name} saved at:\\n{model_path}\")\n",
    "    print(f\"CV metrics report saved at:\\n{metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Daftar file asli\n",
    "files = [\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_apf.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_maccs.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_apf.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_macckeys.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_APF.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_MACCS.pkl\"\n",
    "]\n",
    "\n",
    "for filepath in files:\n",
    "    dir_name = os.path.dirname(filepath)\n",
    "    base_name = os.path.basename(filepath)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    \n",
    "    # Sisipkan \"Resp\" di awal nama file\n",
    "    new_name = f\"Resp_{name}{ext}\"\n",
    "    new_path = os.path.join(dir_name, new_name)\n",
    "    \n",
    "    os.rename(filepath, new_path)\n",
    "    print(f\"Renamed:\\n{filepath}\\n -> {new_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.int32((S))\n",
    "x_macckeys = np.array(list(combined_df['MACCS_Descriptors']))\n",
    "x_morgan = np.array(list(combined_df['Morgan_Descriptors']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physicochemical Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Molecule ChEMBL ID Molecule Name  Molecule Max Phase  Molecular Weight  \\\n",
      "0      CHEMBL4059999           NaN                   0            300.29   \n",
      "1      CHEMBL1972860    ELESCLOMOL                   3            400.53   \n",
      "2       CHEMBL573107           NaN                   0            391.42   \n",
      "3      CHEMBL4084120           NaN                   0            609.77   \n",
      "4       CHEMBL577784        BX-795                   0            591.48   \n",
      "\n",
      "   #RO5 Violations  AlogP Compound Key  \\\n",
      "0              0.0   3.57           3g   \n",
      "1              0.0   2.05   Elesclomol   \n",
      "2              0.0   3.42     BI-D1870   \n",
      "3              1.0   3.57            2   \n",
      "4              1.0   4.75       BX-795   \n",
      "\n",
      "                                              Smiles Standard Type  \\\n",
      "0           CCc1c(-c2ccc(O)c(F)c2)c(=O)oc2cc(O)ccc12          IC50   \n",
      "1    CN(NC(=O)CC(=O)NN(C)C(=S)c1ccccc1)C(=S)c1ccccc1          IC50   \n",
      "2  CC(C)CCN1c2nc(Nc3cc(F)c(O)c(F)c3)ncc2N(C)C(=O)C1C          IC50   \n",
      "3  CC[C@H](NC)C(=O)N[C@@H]1C(=O)N2[C@H](CC[C@H]2C...          IC50   \n",
      "4  O=C(NCCCNc1nc(Nc2cccc(NC(=O)N3CCCC3)c2)ncc1I)c...          IC50   \n",
      "\n",
      "  Standard Relation  ...  Target Name Target Organism  Target Type  \\\n",
      "0               '='  ...   MDA-MB-453    Homo sapiens    CELL-LINE   \n",
      "1               '='  ...   MDA-MB-453    Homo sapiens    CELL-LINE   \n",
      "2               '='  ...   MDA-MB-453    Homo sapiens    CELL-LINE   \n",
      "3               '>'  ...   MDA-MB-453    Homo sapiens    CELL-LINE   \n",
      "4               '='  ...   MDA-MB-453    Homo sapiens    CELL-LINE   \n",
      "\n",
      "  Document ChEMBL ID Source ID  \\\n",
      "0      CHEMBL4033683         1   \n",
      "1      CHEMBL1201861         5   \n",
      "2      CHEMBL1201861         5   \n",
      "3      CHEMBL4017482         1   \n",
      "4      CHEMBL1201861         5   \n",
      "\n",
      "                                  Source Description      Document Journal  \\\n",
      "0                              Scientific Literature       Bioorg Med Chem   \n",
      "1  Sanger Institute Genomics of Drug Sensitivity ...                   NaN   \n",
      "2  Sanger Institute Genomics of Drug Sensitivity ...                   NaN   \n",
      "3                              Scientific Literature  Bioorg Med Chem Lett   \n",
      "4  Sanger Institute Genomics of Drug Sensitivity ...                   NaN   \n",
      "\n",
      "   Document Year  Cell ChEMBL ID  Properties  \n",
      "0         2017.0   CHEMBL3307596         NaN  \n",
      "1            NaN   CHEMBL3307596         NaN  \n",
      "2            NaN   CHEMBL3307596         NaN  \n",
      "3         2017.0   CHEMBL3307596         NaN  \n",
      "4            NaN   CHEMBL3307596         NaN  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-453_raw.csv\"\n",
    "\n",
    "# biar pandas deteksi separator otomatis\n",
    "df = pd.read_csv(input_path, sep=None, engine='python')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MCF-7_raw.csv with shape (72894, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MCF-7_cleaned.csv\n",
      "\n",
      "Loaded MDA-MB-231_raw.csv with shape (44789, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MDA-MB-231_cleaned.csv\n",
      "\n",
      "Loaded MDA-MB-361_raw.csv with shape (605, 45)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MDA-MB-361_cleaned.csv\n",
      "\n",
      "Loaded MDA-MB-435_raw.csv with shape (32939, 45)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MDA-MB-435_cleaned.csv\n",
      "\n",
      "Loaded MDA-MB-453_raw.csv with shape (575, 45)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MDA-MB-453_cleaned.csv\n",
      "\n",
      "Loaded MDA-MB-468_raw.csv with shape (2651, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\MDA-MB-468_cleaned.csv\n",
      "\n",
      "Loaded SK-BR-3_raw.csv with shape (2982, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\SK-BR-3_cleaned.csv\n",
      "\n",
      "Loaded T-47D_raw.csv with shape (31131, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\T-47D_cleaned.csv\n",
      "\n",
      "Loaded Bcap37_raw.csv with shape (559, 45)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\Bcap37_cleaned.csv\n",
      "\n",
      "Loaded BT-20_raw.csv with shape (349, 45)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\BT-20_cleaned.csv\n",
      "\n",
      "Loaded BT-474_raw.csv with shape (984, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\BT-474_cleaned.csv\n",
      "\n",
      "Loaded BT-549_raw.csv with shape (26915, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\BT-549_cleaned.csv\n",
      "\n",
      "Loaded HBL-100_raw.csv with shape (472, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\HBL-100_cleaned.csv\n",
      "\n",
      "Loaded Hs-578T_raw.csv with shape (27150, 41)\n",
      "Saved cleaned CSV: C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\\Hs-578T_cleaned.csv\n",
      "\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 1. Daftar semua file CSV mentah\n",
    "# ================================\n",
    "raw_files = [\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MCF-7_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-231_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-361_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-435_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-453_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\MDA-MB-468_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\SK-BR-3_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\T-47D_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\Bcap37_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\BT-20_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\BT-474_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\BT-549_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\HBL-100_raw.csv\",\n",
    "    r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Raw_dataset\\Hs-578T_raw.csv\"\n",
    "]\n",
    "\n",
    "output_folder = r\"C:\\Fauzan\\Research Grant Daewong\\Efficacy Prediction\\Dataset\\Cleaned_dataset\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ================================\n",
    "# 2. Loop setiap file, bersihkan, dan simpan\n",
    "# ================================\n",
    "for file_path in raw_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=None, engine='python')  # auto-detect separator\n",
    "        print(f\"Loaded {os.path.basename(file_path)} with shape {df.shape}\")\n",
    "\n",
    "        # ================================\n",
    "        # Bersihkan data\n",
    "        # ================================\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                try:\n",
    "                    df[col] = pd.to_numeric(df[col].str.replace(',','').str.replace(' ',''))\n",
    "                except:\n",
    "                    df[col] = df[col].astype(str).fillna('')\n",
    "            else:\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        # Strip whitespace di string\n",
    "        str_cols = df.select_dtypes(include='object').columns\n",
    "        for col in str_cols:\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "        # ================================\n",
    "        # Simpan file bersih\n",
    "        # ================================\n",
    "        clean_path = os.path.join(output_folder, os.path.basename(file_path).replace('_raw','_cleaned'))\n",
    "        df.to_csv(clean_path, index=False)\n",
    "        print(f\"Saved cleaned CSV: {clean_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\\n\")\n",
    "\n",
    "print(\"All files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
